{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import xml.etree.ElementTree as ET\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "medals_data = pd.read_excel('data/olympic_medals.xlsx')\n",
    "hosts_data = pd.read_xml('data/olympic_hosts.xml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.merge(medals_data, hosts_data, left_on='slug_game', right_on='game_slug')\n",
    "\n",
    "summer_data = merged_data[merged_data['game_season'] == 'Summer']\n",
    "\n",
    "summer_medals = summer_data.groupby('country_name').agg({\n",
    "    'medal_type': lambda x: (x == 'GOLD').sum(),\n",
    "    'slug_game': 'count'\n",
    "}).rename(columns={'medal_type': 'gold_medals', 'slug_game': 'total_medals'})\n",
    "\n",
    "summer_medals['silver_medals'] = summer_data.groupby('country_name')['medal_type'].apply(lambda x: (x == 'SILVER').sum())\n",
    "summer_medals['bronze_medals'] = summer_data.groupby('country_name')['medal_type'].apply(lambda x: (x == 'BRONZE').sum())\n",
    "\n",
    "X = summer_medals[['gold_medals', 'silver_medals', 'bronze_medals', 'total_medals']].values\n",
    "y = summer_medals[['gold_medals', 'silver_medals', 'bronze_medals']].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_2024 = np.array([[10, 5, 7, 22]])\n",
    "X_2024_scaled = scaler.transform(X_2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prédictions avec Decision Tree: [[3. 7. 9.]]\n"
     ]
    }
   ],
   "source": [
    "# Modèle 1: Decision Tree\n",
    "tree_model = DecisionTreeRegressor(random_state=42)\n",
    "tree_model.fit(X_train, y_train)\n",
    "y_pred_tree = tree_model.predict(X_2024)\n",
    "print(\"Prédictions avec Decision Tree:\", y_pred_tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prédictions avec Random Forest: [[5.51 6.14 8.41]]\n"
     ]
    }
   ],
   "source": [
    "# Modèle 2: Random Forest\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_2024)\n",
    "print(\"Prédictions avec Random Forest:\", y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prédictions avec SVM: [[9.92438798 5.00466123 7.00365977]]\n"
     ]
    }
   ],
   "source": [
    "# Modèle 3: Support Vector Machine (SVM)\n",
    "svm_gold = SVR(kernel='linear')\n",
    "svm_silver = SVR(kernel='linear')\n",
    "svm_bronze = SVR(kernel='linear')\n",
    "\n",
    "svm_gold.fit(X_train, y_train[:, 0])\n",
    "svm_silver.fit(X_train, y_train[:, 1])\n",
    "svm_bronze.fit(X_train, y_train[:, 2])\n",
    "\n",
    "y_pred_svm_gold = svm_gold.predict(X_2024)\n",
    "y_pred_svm_silver = svm_silver.predict(X_2024)\n",
    "y_pred_svm_bronze = svm_bronze.predict(X_2024)\n",
    "\n",
    "y_pred_svm = np.array([y_pred_svm_gold, y_pred_svm_silver, y_pred_svm_bronze]).T\n",
    "print(\"Prédictions avec SVM:\", y_pred_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 1s 64ms/step - loss: 13374.9805 - val_loss: 1863.5985\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 13348.5713 - val_loss: 1859.1223\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 13310.2705 - val_loss: 1854.7102\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 13273.6494 - val_loss: 1849.8562\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 13230.3174 - val_loss: 1844.3876\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 13189.4688 - val_loss: 1837.8275\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 13141.3369 - val_loss: 1829.9108\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 13074.9609 - val_loss: 1820.6451\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 12991.2148 - val_loss: 1810.2914\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 12900.7422 - val_loss: 1798.2834\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 12830.8965 - val_loss: 1783.4642\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 12679.7646 - val_loss: 1768.1469\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 12577.9951 - val_loss: 1749.6483\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 12409.8564 - val_loss: 1730.1302\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 12293.0361 - val_loss: 1707.1045\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 12128.3447 - val_loss: 1681.3042\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 11891.4541 - val_loss: 1654.2578\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 11668.8223 - val_loss: 1624.7699\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 11461.4922 - val_loss: 1590.7111\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 11174.3457 - val_loss: 1554.0028\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 10860.8350 - val_loss: 1513.4438\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 10613.8818 - val_loss: 1466.6505\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 10187.4590 - val_loss: 1418.9576\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 9781.7393 - val_loss: 1366.9054\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 9352.2666 - val_loss: 1311.7300\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 8918.5371 - val_loss: 1252.6614\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 8410.6855 - val_loss: 1189.9341\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 8007.5718 - val_loss: 1117.6174\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7581.0156 - val_loss: 1039.7543\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 6920.3481 - val_loss: 963.0424\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6412.8179 - val_loss: 881.6926\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5786.2363 - val_loss: 800.4340\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5261.2285 - val_loss: 715.0170\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 4503.9253 - val_loss: 635.4971\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 4149.3311 - val_loss: 546.3122\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 3533.9778 - val_loss: 462.7195\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 2840.3225 - val_loss: 388.4333\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2301.0474 - val_loss: 319.7475\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1931.8544 - val_loss: 253.3873\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1499.2336 - val_loss: 196.8866\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1043.6182 - val_loss: 153.3075\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 873.6251 - val_loss: 115.3544\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 633.4056 - val_loss: 88.3602\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 459.6418 - val_loss: 70.6842\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 354.1418 - val_loss: 59.7956\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 318.7245 - val_loss: 53.2249\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 289.8399 - val_loss: 49.3657\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 278.7265 - val_loss: 46.8966\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 272.0475 - val_loss: 45.3261\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 265.5915 - val_loss: 44.4443\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 254.5305 - val_loss: 43.9211\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 246.8496 - val_loss: 43.9242\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 236.6918 - val_loss: 44.1070\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 230.3402 - val_loss: 44.5968\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 224.7150 - val_loss: 45.1275\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 223.2932 - val_loss: 45.9162\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 217.2378 - val_loss: 46.4637\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 214.1875 - val_loss: 46.9581\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 210.7985 - val_loss: 47.1547\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 210.2076 - val_loss: 47.7759\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 207.9339 - val_loss: 48.2262\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 204.9852 - val_loss: 48.3742\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 205.5796 - val_loss: 48.9189\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 202.3945 - val_loss: 49.0155\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 201.7287 - val_loss: 49.3543\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 201.8206 - val_loss: 49.7774\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 200.0372 - val_loss: 49.8493\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 199.2199 - val_loss: 49.8790\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 198.8753 - val_loss: 49.7076\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 198.4867 - val_loss: 50.0197\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 197.8384 - val_loss: 50.1639\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 197.1647 - val_loss: 49.9985\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 196.9552 - val_loss: 50.2419\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 196.1478 - val_loss: 50.2182\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 196.2033 - val_loss: 50.3558\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 195.6512 - val_loss: 50.3854\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 195.4581 - val_loss: 49.9506\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 195.0040 - val_loss: 50.0712\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 194.6432 - val_loss: 50.1575\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 194.0251 - val_loss: 49.7964\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 193.7341 - val_loss: 49.5096\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 193.3049 - val_loss: 49.5104\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 192.6356 - val_loss: 49.3336\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 192.4023 - val_loss: 49.0684\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 192.2054 - val_loss: 48.6567\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 192.0082 - val_loss: 48.8316\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 191.3915 - val_loss: 48.4687\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 190.5719 - val_loss: 48.3709\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 190.8999 - val_loss: 48.5974\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 189.8615 - val_loss: 48.4858\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 190.0601 - val_loss: 47.9523\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 188.9599 - val_loss: 47.7927\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 188.3151 - val_loss: 47.8516\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 188.5289 - val_loss: 48.0341\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 187.6050 - val_loss: 47.7316\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 186.8924 - val_loss: 47.4782\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 186.3123 - val_loss: 47.3205\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 185.8141 - val_loss: 47.0962\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 186.2935 - val_loss: 46.4674\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 185.0356 - val_loss: 46.2161\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "Prédictions avec MLP: [[4.1409245 5.333446  7.434516 ]]\n"
     ]
    }
   ],
   "source": [
    "# Modèle 4: Multilayer Perceptron (MLP)\n",
    "mlp_model = Sequential()\n",
    "mlp_model.add(Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "mlp_model.add(Dense(64, activation='relu'))\n",
    "mlp_model.add(Dense(3, activation='linear'))\n",
    "\n",
    "mlp_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "mlp_model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_data=(X_test_scaled, y_test))\n",
    "\n",
    "y_pred_mlp = mlp_model.predict(X_2024_scaled)\n",
    "print(\"Prédictions avec MLP:\", y_pred_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    }
   ],
   "source": [
    "# Comparaison des modèles\n",
    "models = {\n",
    "    \"Decision Tree\": tree_model,\n",
    "    \"Random Forest\": rf_model,\n",
    "    \"SVM (Gold)\": svm_gold,\n",
    "    \"SVM (Silver)\": svm_silver,\n",
    "    \"SVM (Bronze)\": svm_bronze,\n",
    "    \"MLP\": mlp_model\n",
    "}\n",
    "\n",
    "metrics = {}\n",
    "for model_name, model in models.items():\n",
    "    if model_name == \"MLP\":\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "        metrics[model_name] = {\n",
    "            \"RMSE\": np.sqrt(mean_squared_error(y_test, y_pred)),\n",
    "            \"MAE\": mean_absolute_error(y_test, y_pred),\n",
    "            \"R²\": r2_score(y_test, y_pred)\n",
    "        }\n",
    "    elif \"SVM\" in model_name:\n",
    "        if \"Gold\" in model_name:\n",
    "            y_pred = model.predict(X_test)\n",
    "            true_values = y_test[:, 0]\n",
    "        elif \"Silver\" in model_name:\n",
    "            y_pred = model.predict(X_test)\n",
    "            true_values = y_test[:, 1]\n",
    "        elif \"Bronze\" in model_name:\n",
    "            y_pred = model.predict(X_test)\n",
    "            true_values = y_test[:, 2]\n",
    "        \n",
    "        metrics[model_name] = {\n",
    "            \"RMSE\": np.sqrt(mean_squared_error(true_values, y_pred)),\n",
    "            \"MAE\": mean_absolute_error(true_values, y_pred),\n",
    "            \"R²\": r2_score(true_values, y_pred)\n",
    "        }\n",
    "    else:\n",
    "        y_pred = model.predict(X_test)\n",
    "        metrics[model_name] = {\n",
    "            \"RMSE\": np.sqrt(mean_squared_error(y_test, y_pred)),\n",
    "            \"MAE\": mean_absolute_error(y_test, y_pred),\n",
    "            \"R²\": r2_score(y_test, y_pred)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Decision Tree:\n",
      "  RMSE: 6.568906882762809\n",
      "  MAE: 3.021505376344086\n",
      "  R²: 0.9679235473758162\n",
      "Metrics for Random Forest:\n",
      "  RMSE: 3.748531755578529\n",
      "  MAE: 1.9780645161290324\n",
      "  R²: 0.9899796559724399\n",
      "Metrics for SVM (Gold):\n",
      "  RMSE: 0.06546769317700203\n",
      "  MAE: 0.06345999187873272\n",
      "  R²: 0.9999967737794828\n",
      "Metrics for SVM (Silver):\n",
      "  RMSE: 0.023601827185278475\n",
      "  MAE: 0.015077975206972882\n",
      "  R²: 0.9999995711802342\n",
      "Metrics for SVM (Bronze):\n",
      "  RMSE: 0.022905158816686012\n",
      "  MAE: 0.01779970282734913\n",
      "  R²: 0.9999996839583136\n",
      "Metrics for MLP:\n",
      "  RMSE: 6.79824357832811\n",
      "  MAE: 4.555787078795895\n",
      "  R²: 0.967942981248486\n"
     ]
    }
   ],
   "source": [
    "for model_name, model_metrics in metrics.items():\n",
    "    print(f\"Metrics for {model_name}:\")\n",
    "    for metric_name, metric_value in model_metrics.items():\n",
    "        print(f\"  {metric_name}: {metric_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prédictions avec Random Forest pour le Top 25 des pays participants: [[2.31 4.21 4.9 ]\n",
      " [1.02 1.7  1.97]\n",
      " [0.97 1.81 1.93]\n",
      " [0.48 1.28 1.84]\n",
      " [0.48 1.28 1.84]\n",
      " [1.06 1.05 0.69]\n",
      " [0.74 0.86 1.51]\n",
      " [0.5  0.83 1.59]\n",
      " [0.35 0.87 0.9 ]\n",
      " [0.31 0.87 0.92]\n",
      " [0.35 0.87 0.9 ]\n",
      " [0.31 0.87 0.92]\n",
      " [0.31 0.87 0.92]\n",
      " [0.   0.9  0.92]\n",
      " [0.   0.9  0.92]\n",
      " [0.31 0.87 0.92]\n",
      " [0.   0.9  0.92]\n",
      " [0.   0.9  0.92]\n",
      " [0.   0.   1.  ]\n",
      " [0.18 0.67 0.27]\n",
      " [0.18 0.67 0.27]\n",
      " [0.18 0.67 0.27]\n",
      " [0.18 0.67 0.27]\n",
      " [0.18 0.67 0.27]\n",
      " [0.18 0.67 0.27]]\n"
     ]
    }
   ],
   "source": [
    "top_25_countries = summer_medals.nlargest(25, 'total_medals')\n",
    "X_top_25 = top_25_countries[['gold_medals', 'silver_medals', 'bronze_medals', 'total_medals']].values\n",
    "X_top_25_scaled = scaler.transform(X_top_25)\n",
    "\n",
    "y_pred_top_25_rf = rf_model.predict(X_top_25_scaled)\n",
    "print(\"Prédictions avec Random Forest pour le Top 25 des pays participants:\", y_pred_top_25_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prédictions avec Random Forest pour les athlètes: [[0.27 1.34 1.89]\n",
      " [0.04 0.   0.01]\n",
      " [0.97 0.03 0.16]\n",
      " [0.97 0.03 0.16]\n",
      " [2.   2.   0.  ]\n",
      " [1.94 1.   0.04]\n",
      " [2.   0.01 0.  ]\n",
      " [1.11 0.01 1.99]\n",
      " [1.98 0.11 0.91]\n",
      " [0.98 0.07 0.91]\n",
      " [1.79 0.1  1.99]\n",
      " [1.75 0.13 1.97]\n",
      " [0.88 1.07 1.05]\n",
      " [0.13 1.05 0.97]\n",
      " [1.99 1.99 0.05]\n",
      " [0.02 0.03 0.  ]\n",
      " [0.35 1.84 0.13]\n",
      " [2.   0.99 1.01]\n",
      " [2.   2.   0.01]\n",
      " [1.02 1.   0.02]]\n",
      "Metrics pour la prédiction des athlètes:\n",
      "  RMSE: 0.127501633976458\n",
      "  MAE: 0.06966666666666667\n",
      "  R²: 0.9757512499496962\n"
     ]
    }
   ],
   "source": [
    "athlete_data = pd.DataFrame({\n",
    "    'athlete_id': np.arange(1, 101),\n",
    "    'past_performance': np.random.rand(100),\n",
    "    'gold_medals': np.random.randint(0, 3, size=100),\n",
    "    'silver_medals': np.random.randint(0, 3, size=100),\n",
    "    'bronze_medals': np.random.randint(0, 3, size=100)\n",
    "})\n",
    "\n",
    "X_athletes = athlete_data[['past_performance', 'gold_medals', 'silver_medals', 'bronze_medals']].values\n",
    "y_athletes = athlete_data[['gold_medals', 'silver_medals', 'bronze_medals']].values\n",
    "\n",
    "X_athletes_train, X_athletes_test, y_athletes_train, y_athletes_test = train_test_split(X_athletes, y_athletes, test_size=0.2, random_state=42)\n",
    "\n",
    "rf_model_athletes = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model_athletes.fit(X_athletes_train, y_athletes_train)\n",
    "y_pred_athletes_rf = rf_model_athletes.predict(X_athletes_test)\n",
    "print(\"Prédictions avec Random Forest pour les athlètes:\", y_pred_athletes_rf)\n",
    "\n",
    "# Comparaison des prédictions avec les valeurs réelles pour les athlètes\n",
    "athlete_metrics = {\n",
    "    \"RMSE\": np.sqrt(mean_squared_error(y_athletes_test, y_pred_athletes_rf)),\n",
    "    \"MAE\": mean_absolute_error(y_athletes_test, y_pred_athletes_rf),\n",
    "    \"R²\": r2_score(y_athletes_test, y_pred_athletes_rf)\n",
    "}\n",
    "\n",
    "print(\"Metrics pour la prédiction des athlètes:\")\n",
    "for metric_name, metric_value in athlete_metrics.items():\n",
    "    print(f\"  {metric_name}: {metric_value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
